{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e8a22b-738a-4ccb-9e3b-f39dd0e653f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85548d3e-dbb8-4c2b-821d-c32db6a0e4f3",
   "metadata": {},
   "source": [
    "# Get Data (Shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409cc6a9-0837-453f-8b71-b25894d39517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store text in one long string called 'data'\n",
    "f = open(\"./shakespeare.txt\")\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369d9051-9a12-43f7-af76-025041fbe5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to one-hot encode each characters to\n",
    "char2int = dict([(c, i) for i, c in enumerate(set(data))])\n",
    "int2char = dict([(char2int[k], k) for k in char2int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e764fe4a-eade-46fb-92d4-3822080163b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, 'n': 1, 'U': 2, 't': 3, 's': 4, 'K': 5, 'q': 6, 'u': 7, 'g': 8, 'F': 9, 'O': 10, 'N': 11, 'E': 12, 'v': 13, 'e': 14, 'w': 15, 'B': 16, '-': 17, 'W': 18, 'z': 19, ';': 20, '!': 21, ',': 22, 'j': 23, 'r': 24, 'D': 25, 'G': 26, 'l': 27, ')': 28, 'P': 29, 'c': 30, '\\n': 31, 'd': 32, 'M': 33, 'p': 34, 'h': 35, ':': 36, 'T': 37, 'C': 38, 'Y': 39, 'H': 40, 'S': 41, 'y': 42, 'b': 43, 'R': 44, 'a': 45, 'm': 46, 'V': 47, 'i': 48, 'o': 49, ' ': 50, 'f': 51, \"'\": 52, 'L': 53, '?': 54, '(': 55, 'A': 56, 'I': 57, 'k': 58, 'J': 59, 'x': 60}\n",
      "{0: '.', 1: 'n', 2: 'U', 3: 't', 4: 's', 5: 'K', 6: 'q', 7: 'u', 8: 'g', 9: 'F', 10: 'O', 11: 'N', 12: 'E', 13: 'v', 14: 'e', 15: 'w', 16: 'B', 17: '-', 18: 'W', 19: 'z', 20: ';', 21: '!', 22: ',', 23: 'j', 24: 'r', 25: 'D', 26: 'G', 27: 'l', 28: ')', 29: 'P', 30: 'c', 31: '\\n', 32: 'd', 33: 'M', 34: 'p', 35: 'h', 36: ':', 37: 'T', 38: 'C', 39: 'Y', 40: 'H', 41: 'S', 42: 'y', 43: 'b', 44: 'R', 45: 'a', 46: 'm', 47: 'V', 48: 'i', 49: 'o', 50: ' ', 51: 'f', 52: \"'\", 53: 'L', 54: '?', 55: '(', 56: 'A', 57: 'I', 58: 'k', 59: 'J', 60: 'x'}\n"
     ]
    }
   ],
   "source": [
    "print(char2int)\n",
    "print(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95e51a5-6a92-471d-a22c-47fc9c68e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode and move to Tensors\n",
    "x_encoded = nn.functional.one_hot((torch.Tensor([char2int[x] for x in data]).long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73184e4f-51c7-405f-a54d-cf353b6e901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of reverting tensor back to single char for use later\n",
    "int2char[np.argmax(x_encoded[1].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8bc739-5312-4d0b-bcef-0ae896e219a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([94275, 61])\n"
     ]
    }
   ],
   "source": [
    "print(x_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112fb62-9ed1-4a51-9be7-7398235b6c01",
   "metadata": {},
   "source": [
    "# Build RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8fad76b8-edeb-47ca-ad8d-14dc6417a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.in_linear = nn.Linear(61, self.hidden_dim, bias=False)\n",
    "        self.hid_linear = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.out_linear = nn.Linear(self.hidden_dim, 61)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        if hidden == None:\n",
    "            hidden = torch.zeros(self.hidden_dim).to(device)\n",
    "        \n",
    "        ht = nn.functional.relu(self.in_linear(x) + self.hid_linear(hidden))\n",
    "        ot = self.out_linear(ht)\n",
    "        return ht, ot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c16d3365-0fc6-4b4e-a7db-16cf52ac89df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbedcb9-a5b7-43ce-989c-5f7850f7d696",
   "metadata": {},
   "source": [
    "# Set System Standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "494ca9bd-34b4-4c0a-9020-25292afe50a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# set device for pytorch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# set loss function as cross entropy loss, optimizer and SGD\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bae6b78b-639a-4d64-b078-f77d379d6a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move everything to CUDA\n",
    "model = model.to(device)\n",
    "x_encoded = x_encoded.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5ebbb760-c30f-4974-b6e8-5f73ba6328f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def train(model, criterion, optimizer, data):\n",
    "\n",
    "    hidden = None\n",
    "    correct = 0\n",
    "    \n",
    "    # set to train mode\n",
    "    model.train()\n",
    "    for i in range(len(data)):\n",
    "        # skip first index, since at this point we have no context to train with\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        # label is the current char data[i] and input is the previous char data[i-1]\n",
    "        optimizer.zero_grad()\n",
    "        hidden, pred = model(data[i-1], None)\n",
    "        loss = criterion(pred, data[i])\n",
    "        \n",
    "        correct += np.argmax(pred.tolist())==np.argmax(data[i].tolist())\n",
    "\n",
    "        # grad. descent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%10000==0:\n",
    "            print(f\"accuracy={correct/10000.0}\")\n",
    "            correct = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b9b6aeb1-4e91-45a4-9e05-d8ac5c1fc148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -----------------------------------\n",
      "accuracy=0.2845\n",
      "accuracy=0.2917\n",
      "accuracy=0.2945\n",
      "accuracy=0.2763\n",
      "accuracy=0.2854\n",
      "accuracy=0.2825\n",
      "accuracy=0.2704\n",
      "accuracy=0.2697\n",
      "accuracy=0.2868\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t} -----------------------------------\")\n",
    "    train(model, criterion, optimizer, x_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339b22e-6984-4af5-a158-ee18cbebc9e1",
   "metadata": {},
   "source": [
    "# Generate Text from Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c49ff6bd-1291-4514-ab83-238fce04253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to eval mode here to prevent gradients from being calculated\n",
    "model.eval()\n",
    "\n",
    "# extra characters to make\n",
    "generate_size = 100\n",
    "\n",
    "# keep running\n",
    "text = x_encoded[2]\n",
    "text = text.reshape(1, 61)\n",
    "\n",
    "hidden = None\n",
    "for i in range(generate_size):\n",
    "    hidden, next_chr = model(text[i], hidden)\n",
    "    text = torch.cat((text, next_chr.reshape(1, next_chr.shape[0])), dim=0)\n",
    "\n",
    "text_real = [int2char[np.argmax(text[i].tolist())] for i in range(len(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ebc1a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E d   nene  nene e ene e ene e ene e e e e e e e e ..................................................\n"
     ]
    }
   ],
   "source": [
    "print(''.join(text_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d84c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gends",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
